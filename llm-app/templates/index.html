<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Redis Langcache Demo</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='css/styles.css') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/operations-log.css') }}">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">

</head>
<body>
    <header>
        <div class="logo">
            <img src="https://redis.com/wp-content/themes/wpx/assets/images/logo-redis.svg" alt="Redis Logo">
            <h1>Langcache Demo</h1>
        </div>
    </header>

    <div class="app-container">
        <!-- No Side Panel -->
        <div class="side-panel" style="display: none;">
            <div class="tabs">
                <button class="tab-button active" data-tab="demo">Demo</button>
            </div>
        </div>

        <!-- Main Content Area -->
        <main>
        <!-- Demo Tab Content -->
        <div class="tab-content" id="demo-content" style="display: block;">
        <div class="description">
            <h2>Langcache Demo</h2>
            <p>This demo shows how Redis Langcache works with Google's Gemini model to provide fast, semantically-cached responses.</p>
        </div>

        <div class="model-selection">
            <div class="model-dropdown">
                <label for="llm-model">LLM Model:</label>
                <select id="llm-model">
                    <option value="gemini-1.5-flash" selected>Google Gemini Flash 1.5</option>
                    <option value="gpt-4o">OpenAI GPT-4o</option>
                </select>
            </div>
            <div class="model-dropdown">
                <label for="embedding-model">Embedding Model:</label>
                <select id="embedding-model">
                    <option value="redis-langcache" selected>Redis: langcache-embed-v1</option>
                    <option value="openai-embeddings">OpenAI: text-embedding-3-small</option>
                    <option value="ollama-bge">Ollama: bge-m3</option>
                </select>
            </div>
        </div>

        <div class="query-section">
            <div class="query-input">
                <input type="text" id="query-input" placeholder="Enter your question here...">
                <button id="submit-query">Ask</button>
            </div>
        </div>

        <div class="panels-container">
            <div class="panel cached">
                <div class="panel-header">
                    <h3>Semantic Cache Panel</h3>
                    <div class="performance-indicator">
                        <span class="response-time" id="cached-time"></span>
                    </div>
                </div>
                <div class="chat-container" id="cached-chat">
                    <div class="welcome-message">
                        <p>Using Redis Langcache with Google's Gemini LLM.</p>
                        <p>Similar queries will be retrieved instantly from cache!</p>
                        <p><strong>âœ“ Retrieved from Redis semantic cache</strong> will appear at the top when a cached response is found.</p>
                        <p><strong>Generated by LLM</strong> will appear when a new response is generated.</p>
                    </div>
                </div>
            </div>
        </div>

        <div class="how-it-works">
            <h3>How It Works</h3>
            <div class="workflow">
                <div class="workflow-step">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h4>User Query</h4>
                        <p>You enter a question that gets processed by the semantic cache system.</p>
                    </div>
                </div>
                <div class="workflow-step">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h4>Semantic Cache Check</h4>
                        <p>The system checks Redis for semantically similar previous queries.</p>
                    </div>
                </div>
                <div class="workflow-step">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h4>Response Delivery</h4>
                        <p>If a similar query is found, the cached response appears instantly. Otherwise, a new response is generated by the LLM and stored in the cache for future use.</p>
                    </div>
                </div>
            </div>
        </div>
    </div>
    </main>
</div>

<footer>
    <p>Redis Semantic Cache Demo | <a href="https://redis.com" target="_blank">Redis</a> | <a href="/log">View Cache Log</a></p>
</footer>

<script src="{{ url_for('static', filename='js/main.js') }}"></script>
</body>
</html>
